<!DOCTYPE HTML>
<html>
	<head>
		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-0FFN6N7318"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-0FFN6N7318');
		</script>
		<title>Introducing LLM360: Fully Transparent open-source LLMs | LLM360</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>

		<!-- Favicon -->
		<link rel="icon" type="image/x-icon" href="../assets/favicon/favicon.ico" />
    <link rel="icon" type="image/png" sizes="192x192" href="../assets/favicon/android-chrome-192x192.png">
    <link rel="icon" type="image/png" sizes="512x512" href="../assets/favicon/android-chrome-512x512.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../assets/favicon/favicon-16x16.png">
    <link rel="apple-touch-icon" sizes="180x180" href="../assets/favicon/apple-touch-icon.png">
    <!-- <link rel="manifest" href="/site.webmanifest"> -->
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">

	</head>
	<body class="no-sidebar is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
					<a href="../index.html" class="logo">
						<span class="symbol"><img src="../images/logo_webheader.png" alt="" /></span><span>LLM360</span>
					</a>
					<nav id="nav">
						<ul>
							<li class="current"><a href="../index.html">Home</a></li>
							<li>
								<a>Models</a>
								<ul>
									<li>
										<a>Amber</a>
										<ul>
											<li><a href="https://short.llm360.ai/amber-model" target="_blank">Model</a></li>
											<li><a href="https://wandb.ai/llm360/Amber" target="_blank">Metrics</a></li>
											<li><a href="https://short.llm360.ai/amber-data" target="_blank">Data</a></li>
											<li><a href="https://short.llm360.ai/amber-code" target="_blank">Code</a></li>
										</ul>
									</li>
									<li>
										<a>CrystalCoder</a>
										<ul>
											<li><a href="https://short.llm360.ai/crystalcoder-model" target="_blank">Model</a></li>
											<li><a href="https://wandb.ai/llm360/CrystalCoder" target="_blank">Metrics</a></li>
											<li><a href="https://short.llm360.ai/crystalcoder-data" target="_blank">Data</a></li>
											<li><a href="https://short.llm360.ai/crystalcoder-code" target="_blank">Code</a></li>
										</ul>
									</li>
									<li>
										<a>Diamond (Coming Soon)</a>
										<!--
										<ul>
											<li><a href="https://huggingface.co/LLM360/llm360-temp">Model</a></li>
											<li><a href="https://github.com/LLM360">Analysis</a></li>
											<li><a href="https://huggingface.co/LLM360/llm360-temp">Data</a></li>
											<li><a href="https://github.com/LLM360">Code</a></li>
										</ul>
										-->
									</li>
								</ul>
							</li>
							<li>
								<a href="#">Research</a>
								<ul>
									<li><a href="../paper.pdf" target="_blank">Paper</a></li>
								</ul>
							</li>
							<li><a href="#">Blog</a></li>
							<li><a href="../index.html#cta">Contact</a></li>
						</ul>
					</nav>
				</header>

			<!-- Main -->
				<article id="blog" class="blog">
					<header class="special container">
						<span class="icon solid fa-blog"></span>

						<h1>Introducing <strong>LLM360</strong>: Fully Transparent Open-Source LLMs</h1>
						<h3 class="author">LLM360 Team      |      December 11, 2023</h3>
					</header>
					<!-- One -->
						<section class="wrapper style5 container">
							<div class="hero">
								<img src="../images/blog-banner.png" style="margin-bottom: 2em"/>
							</div>
							<h2>Introduction</h2>
							<p>
                                In recent months, the open-source large language model
                                (LLM) community has seen tremendous model contributions.
                                However, model weight releases and overview technical
                                reports do not contain enough information to cover the
                                complexity of LLM training, which hinders openness and
                                transparency, the mechanisms behind trustworthy and
                                innovative research and science for decades.
							</p>
							<p>
                                To this end, we are thrilled to introduce LLM360, an
                                initiative to open source LLMs that fosters
                                transparency, trust, and collaborative research.  When
                                releasing models under LLM360, we strive to make all the
                                details of LLM accessible to everyone.
							</p>
							<p>
                                Most open-source LLM releases include model weights and
                                evaluation results.
                                However, additional information is often needed to
                                genuinely understand a model's behavior—and this
                                information is not typically available to most
                                researchers.
                                Hence, we commit to releasing all of the intermediate
                                checkpoints (up to 360!) collected during training, all
                                of the training data (and its mapping to checkpoints),
                                all collected metrics (e.g., loss, gradient norm,
                                evaluation results), and all source code for
                                preprocessing data and model training.
                                These additional artifacts can help researchers and
                                practitioners to have a deeper look into LLM’s
                                construction process and conduct research such as
                                analyzing model dynamics.
                                We hope that LLM360 can help make advanced LLMs more
                                transparent, foster research in smaller-scale labs, and
                                improve reproducibility in AI research.
							</p>
							<p>
                                To start, we are releasing two models under LLM360:
                                Amber-7B and CrystalCoder-7B, which we hope epitomize
                                the spirit of open-source and transparent AI
                                development.
							</p>
							<p>
								LLM360 is a collaboration between <a href="https://petuum.com/" target="_blank">Petuum</a>, <a href="https://mbzuai.ac.ae/" target="_blank">MBZUAI</a>, and <a href="https://www.cerebras.net/" target="_blank">Cerebras</a>.
							</p>
							<br>
<!--							<header class="location container" style="margin-top: 3em">-->
<!--								<div class="row aln-middle">-->
<!--&lt;!&ndash;									<h1>Introducing <strong>LLM 360 </strong>: Fully Transparent open-source LLMs</h1>&ndash;&gt;-->
<!--									<div class="col-8 col-12-narrower left">-->
<!--&lt;!&ndash;										<h3 class="author" style="margin-bottom: 1.5em"> <strong>Author: LLM360 Team</strong></h3>&ndash;&gt;-->
<!--										<p>LLM360 is an initiative to open-source large language models (LLMs) that foster transparency, trust, and collaborative research. Models released under LLM360 are open-source in the true sense of the word, with their training source code and data publicly disclosed and made openly available. We also strive to make the entire training process of LLM360 models transparent, releasing up to 360 intermediate checkpoints collected during the training of our two initial models (Amber and CrystalCoder). Our goal with LLM360 is to make advanced LLMs more transparent, foster research in smaller-scale labs, and improve reproducibility in AI research. LLM360 is a collaboration between Petuum, MBZUAI, and Cerebras.</p>-->
<!--									</div>-->
<!--									<div id="spinButton" class="col-4 col-12-narrower" style="padding-left: 6em">-->
<!--										<img id="spinningImage" src="../images/logo-highres.png" alt="" style="height: 10em; width: auto"/>-->
<!--									</div>-->
<!--								</div>-->
<!--							</header>-->

							<!-- Content -->
								<div class="content left">
									<section>
										<h2>Achieving Transparency and Collaborative Research through LLM360</h2>
										<p>
											The basis of LLM360 is to create a framework that encourages openness and
											research collaboration for large language models. Currently, we include
											all of the following artifacts associated for models in the LLM360 family:

										</p>
											<ul>
												<li><strong>Frequent Intermediate Model Checkpoints:</strong> During training, model parameters and optimizer states are collected regularly. These artifacts can offer valuable insights for studying LLM training dynamics and how it scales with data, and allows one to resume training at various stages.</li>
												<li><strong>Training Data with Full Data Sequence:</strong> The entire preprocessed, tokenized training dataset is fully disclosed and made publicly available. The dataset is presented exactly in correspondence to the training steps.</li>
												<li><strong>Source Code:</strong> All the code used, including data processing, training, evaluation, and analysis.</li>
												<li><strong>Logs and Metrics:</strong> All the training logs,evaluations and analysis results collected during training are publicly disclosed, also in correspondence to the training steps and data sequence.​</li>
											</ul>
											<br>
										<p>
											This is just a beginning to our open source efforts and we are committed to continue providing more details.
											Please don’t hesitate to let us know what you want to know! We are thrilled to receive community feedback to continually refine and augment our releases.
										</p>
										<br>

										<h2>Amber and CrystalCoder Released under LLM360</h2>
										<div class="row aln-middle" style="margin-top: 1em">
											<div class="col-5 col-12-narrower">
												<a class="image fit"><img src="../images/ac_underl360.png" alt="" /></a>
											</div>
											<div class="col-6 col-12-narrower">
												<p>The first two models to be released under LLM360 are Amber and CrystalCoder.
													Amber is a 7B English LLM and CrystalCoder is a 7B code & text LLM.
												</p>
												<p>Both models are released under the Apache 2.0 license.</p>
											</div>
										</div>
										<h4>Amber: Advancing Knowledge and Transparency in LLM Pretraining</h4>
										<p>
											First in the family, Amber is an English LLM  trained on 1.2 trillion tokens
											that performs similarly to LLaMA-7B, OpenLLaMA-v2-7B and outperforms Pythia-6.7B.
										</p>
										<br>
										<div class="row aln-center">
											<div class="col-11" >
                                                <a class="image fit" ><img src="../images/table_amber.png" alt="" /></a>
											</div>
										</div>
										<div class="row aln-center">
											<p><strong>Figure: Open LLM leaderboard comparisons among a few notable LLMs</strong></p>
										</div>
										<p>Amber's true superpower lies in facilitating a knowledge exchange between the training team and the wider community.
											Along with the customary final model weights, Amber is released with 359 additional model checkpoints (360 total) and the per-step data sequence for each checkpoint.
										</p>
										<p>
											Providing access to these intermediate checkpoints can be beneficial to both researchers looking to advance the capability and understanding of LLMs and industry teams who are pretraining or customizing LLMs for enterprise purposes.
										</p>
										<p>
											We will release  more specific learnings and insights from training Amber,
											stay tuned for further posts!. At this moment, we recommend you check out the metrics and analysis below.

										</p>
										<br>
										<div class="row aln-center">
											<a href="https://short.llm360.ai/amber-metrics" target="_blank" class="button button1">Metrics</a>
											<a href="https://short.llm360.ai/amber-data" target="_blank" class="button button1">Data</a>
											<a href="https://short.llm360.ai/amber-code" target="_blank" class="button button1">Code</a>
											<a href="https://short.llm360.ai/amber-model" target="_blank" class="button button1">Model</a>
										</div>
										<div class="row aln-center" style="margin-top: 0.1em">
											<a class="image featured"><img src="../images/amber_logo.png" alt=""/></a>
										</div>
										<br>


										<!-- buttons -->

										<h4>CrystalCoder: Bridging Human Language and Machine Code</h4>
										<p>CrystalCoder is a 7B language model trained on 1.4 trillion tokens, achieving a balance between coding and language ability.</p>
										<br>
										<div class="row aln-center">
											<div class="col-12">
												<a class="image fit"><img src="../images/table_cc.png" alt=""/></a>
											</div>
										</div>
										<div class="row aln-center">
											<p><strong>
												Table 5: Evaluation comparisons among a few notable code and language models.
												The last column is the average of the language task average and the code task average.
												CrystalCoder strikes a good balance between both language and code tasks.
											</strong></p>
										</div>
										<p>Unlike most previous code LLMs, CrystalCoder is trained using a careful mixture of text and code data to maximize utility in both domains.
											Code data is introduced earlier during the pretraining process (as compared with Code Llama 2 which is fine-tuned on Llama 2 using entirely code data).
											Additionally, we trained CrystalCoder on Python and web programming language, to improve its utility as a programming assistant.
										</p>
										<p>Our experiments show that CystalCoder achieves a balanced position between LLaMA 2 and Code LLaMA,
											but with fewer training tokens (LLaMA2 7B is trained on 2T tokens and Code LLaMA is trained with additional 600B tokens).
											The graph below plots the language and coding ability of each model based on the tables above.
											As evidenced by the evaluations, LLaMA 2 regresses in language ability when fine-tuned on code.
											More research is needed to fully understand the phenomena, but studying CrystalCoder may offer some insights.
										</p>
										<br>
										<div class="row aln-center">
											<a class="image fit"><img src="../images/plot.png" alt=""/></a>
										</div>
										<br>
										<p>
											By excelling at both language and code, CrystalCoder proves useful for investigating AI Agent and tool use capabilities.
											CrystalCoder is released with 143 checkpoints and all pre training data.
										</p>
										<p>
											The model was trained on the Condor Galaxy 1 supercomputer built by Cerebras and G42.
										</p>
										<br>
										<div class="row aln-center">
											<a href="https://short.llm360.ai/crystalcoder-metrics" target="_blank" class="button button2">Metrics</a>
											<a href="https://short.llm360.ai/crystalcoder-data" target="_blank" class="button button2">Data</a>
											<a href="https://short.llm360.ai/crystalcoder-code" target="_blank" class="button button2">Code</a>
											<a href="https://short.llm360.ai/crystalcoder-model" target="_blank" class="button button2">Model</a>
										</div>
										<div class="row aln-center" style="margin-top: 0.1em">
											<a class="image featured"><img src="../images/crystalcoder_logo.jpg" alt=""/></a>
										</div>

<!--										<h4>Diamond (Coming Soon)</h4>-->
<!--										<p>65B English LLM trained on 1.4 trillion tokens.</p>-->
										<br>

										<h2>Goals of the LLM360 Framework</h2>
										<p>
											<ul>
												<li><strong>Increased Accessibility:</strong>
													<ul>
														<li>0 GPUs: the community can view all important intermediate results as if training just finished.</li>
														<li>1+ GPUs: intermediate checkpoints can be trained without needing to start from scratch, opening up wider research opportunities.</li>
													</ul>
												</li>
												<li><strong>Research Advancement, Reproducibility, and Model Understanding:</strong>
													<ul>
														<li>We hope this project lays the groundwork for future research by offering complete, reproducible resources.</li>
														<li>By replicating studies and verifying results, we foster a reliable and transparent research environment.</li>
													</ul>
												</li>
												<li><strong>Environmental Responsibility:</strong>
													<ul>
														<li>LLM360 promotes sustainable research by sharing all intermediate results that can be extended upon, thereby reducing unnecessary compute.</li>
													</ul>
												</li>
											</ul>
										</p>
										<br>
										<h2>Collaboration and Community in LLM360</h2>
										<h4>Contributing to the LLM360 Ecosystem</h4>
										<p>LLM360 thrives on community involvement, offering various ways for researchers, developers, and enthusiasts to engage and contribute. Here’s a streamlined guide to getting involved:
										<ul>
											<li><h5> Get Involved:</h5>
												<ul>
													<li><strong>GitHub:</strong> Our <a href="https://github.com/llm360" target="_blank" rel="noopener">GitHub page</a> is the hub for all code related to LLM360. Explore, modify, or use our code and contribute your improvements.</li>
													<li><strong>HuggingFace:</strong> Access and download LLM360 models on <a href="https://huggingface.co/llm360" target="_blank" rel="noopener">HuggingFace</a>. Experiment with them, and share your findings or applications.</li>
												</ul>
											</li>
											<li><h5>Share Your Work:</h5>
												<ul>
													<li><strong>Research Contributions:</strong> If you’ve used Amber or CrystalCoder for research, we encourage you to share your results. Your insights can help enhance these models.</li>
													<li><strong>Share Results:</strong> Your analysis results on any of the checkpoints are more than welcome. Feel free to share with us metrics you compute, we will host selected metrics on our public Weights & Biases dashboard.</li>
												</ul>
											</li>
											<li><h5>Feedback and Suggestions:</h5>
												<ul>
													<li><strong>Feedback Form:</strong> We value your input. <a href="../index.html#cta">Use this form</a> to provide feedback or suggest improvements. Let us know what you want to know more about LLMs!</li>
													<li><strong>Join Discussions:</strong> Engage with peers on our forums. Share experiences, ask questions, and exchange ideas.</li>
												</ul>
											</li>
											<li><h5>Collaborate</h5>
												<ul>
													<li><strong>Partnership Opportunities: </strong>If you're interested in collaborating on a project or have an idea, we’d love to hear from you.</li>
												</ul>
											</li>
										</ul>
										</p>
										<br>

										<h2>What's Ahead for LLM360</h2>
										<p>
											LLM360 is on a mission to expand and deepen the influence of AI research by providing fully accessible, open-source LLMs. We are committed to being fully open and sharing more high quality information on LLMs.
										</p>
										<p>
											Join our global community of researchers, developers, and AI enthusiasts to explore, enhance, and expand models under LLM360.  Together, we can make AI research more open, transparent, and trustworthy.
										</p>
										<br>
										<h2>Resources</h2>
										<ul>
											<li><a href="https://huggingface.co/LLM360" target="_blank" rel="noopener">Download the models</a></li>
											<li><a href="https://github.com/llm360" target="_blank" rel="noopener">Access our codebase</a></li>
											<li><a href="../paper.pdf" target="_blank">Read the paper</a></li>
										</ul>


                                        <br/><br/><br/>
										<h2>Citation</h2>
                                        <p> If you use LLM360, feel free to cite: </p>
<div class="box" background-color="#eee" border="1px" solid="#999" display="block" padding="20px">
<font size="-0.5">
<p>
@article{liu2023llm360,<br/>
title={LLM360: Towards Fully Transparent Open-Source LLMs},<br/>
author={Liu, Zhengzhong and Qiao, Aurick and Neiswanger, Willie and Wang, Hongyi and
Tan, Bowen and Tao, Tianhua and Li, Junbo and Wang, Yuqi and Sun, Suqi and Pagarkar,
Omkar and Fan, Richard and Gu, Yi and Miller, Victor and Zhuang, Yonghao and He, Guowei
and Li, Haonan and Koto, Fajri and Tang, Liping and Ranjan, Nikhil and Shen, Zhiqiang
and Ren, Xuguang and Iriondo, Roberto and Mu, Cun and Hu, Zhiting and Schulze, Mark and
Nakov, Preslav and Baldwin, Tim and Xing, Eric},<br/>
year={2023}}
</p>
</font>
</div>

                                        <!--</div>-->



<!--										<h2>Thank you to Our Partners</h2>-->

<!--									&lt;!&ndash; Supporters &ndash;&gt;-->
<!--										<section class="wrapper style4 container special">-->
<!--											<div class="row aln-center">-->
<!--												<div class="row aln-middle col-4 col-12-mobile">-->
<!--													<a href="https://mbzuai.ac.ae/" target="_blank" rel="noopener" class="image featured"><img src="../images/mbzuai.png" alt="Mohamed bin Zayed University of Artificial Intelligence" /></a>-->
<!--												</div>-->
<!--												<div class="row aln-middle col-4 col-12-mobile">-->
<!--													<a href="https://petuum.com/" target="_blank" rel="noopener" class="image featured"><img src="../images/petuum.png" alt="" /></a>-->
<!--												</div>-->
<!--												<div class="row aln-middle col-2 col-12-mobile">-->
<!--													<a href="https://www.cerebras.net/" target="_blank" rel="noopener" class="image featured"><img src="../images/cerebras.png" alt="" /></a>-->
<!--												</div>-->
<!--											</div>-->
<!--										</section>-->




									</section>
								</div>
						</section>
					<!-- Supporters -->
					<section class="wrapper style4 container special">
						<h1>Thanks to Our Partners</h1>
						<br>
						<div class="row aln-center">
							<div class="row aln-middle col-4 col-12-mobile">
								<a href="https://mbzuai.ac.ae/" target="_blank" rel="noopener" class="image featured"><img src="../images/mbzuai.png" alt="Mohamed bin Zayed University of Artificial Intelligence" /></a>
							</div>
							<div class="row aln-middle col-4 col-12-mobile">
								<a href="https://petuum.com/" target="_blank" rel="noopener" class="image featured"><img src="../images/petuum.png" alt="" /></a>
							</div>
							<div class="row aln-middle col-2 col-12-mobile">
								<a href="https://www.cerebras.net/" target="_blank" rel="noopener" class="image featured"><img src="../images/cerebras.png" alt="" /></a>
							</div>
						</div>
					</section>

				</article>

			<!-- Footer -->
				<footer id="footer">
<!--					<p>LLM 360, a collaboration between Petuum and MBZUAI, is dedicated to advancing the field of AI by providing comprehensive access to large language models.<br>-->
<!--						Our mission is to foster an ecosystem of collaboration, transparency, and innovation in AI research and applications.</p>-->
					<ul class="icons">
						<li><a href="https://twitter.com/llm360" class="icon brands circle fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://github.com/LLM360" class="icon brands circle fa-github"><span class="label">Github</span></a></li>
						<li><a href="mailto:team@llm360.ai" class="icon circle fa-envelope"><span class="label">Email</span></a></li>
					</ul>

					<ul class="copyright">
						<li>&copy; LLM360 2023. All rights reserved</li>
					</ul>
					<a title="Scroll back to top" aria-label="Scroll back to top" href="#" class="back-to-top" hidefocus="true" style="outline: none;">
						<i class="fa fa-chevron-up"></i>
					</a>
				</footer>

		</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.dropotron.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="../assets/js/jquery.scrollgress.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>
