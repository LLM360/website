<!DOCTYPE HTML>
<html lang="en">
	<head>
		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-0FFN6N7318"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-0FFN6N7318');
		</script>

		<title>Introducing LLM360: Fully Transparent open-source LLMs | LLM360</title>
		<meta name="description" content="We are thrilled to introduce LLM360, an initiative to open source LLMs that fosters transparency, trust, and collaborative research. When releasing models under LLM360, we strive to make all the details of LLM accessible to everyone." />
		<link rel="canonical" href="https://www.llm360.ai/blog/introducing-llm360-fully-transparent-open-source-llms.html" />
    <meta name="author" content="Petuum, Mohamed bin Zayed University of Artificial Intelligence"/>
    <meta name="robots" content="index, follow"/>

		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />

		<!-- Favicon -->
		<link rel="icon" type="image/x-icon" href="../assets/favicon/favicon.ico" />
    <link rel="icon" type="image/png" sizes="192x192" href="../assets/favicon/android-chrome-192x192.png">
    <link rel="icon" type="image/png" sizes="512x512" href="../assets/favicon/android-chrome-512x512.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../assets/favicon/favicon-16x16.png">
    <link rel="apple-touch-icon" sizes="180x180" href="../assets/favicon/apple-touch-icon.png">
    <!-- <link rel="manifest" href="/site.webmanifest"> -->
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">

		<!-- Open Graph -->
		<meta property="og:title" content="Introducing LLM360: Fully Transparent Open-Source LLMs" />
		<meta property="og:type" content="article" />
		<meta property="og:url" content="https://www.llm360.ai/blog/introducing-llm360-fully-transparent-open-source-llms.html" />
		<meta property="og:image" content="https://www.llm360.ai/images/blog-banner.png" />
		<meta property="og:description" content="We are thrilled to introduce LLM360, an initiative to open source LLMs that fosters transparency, trust, and collaborative research. When releasing models under LLM360, we strive to make all the details of LLM accessible to everyone." />
		<meta property="og:site_name" content="LLM360" />

		<!-- Twitter Card -->
		<meta name="twitter:card" content="summary_large_image">
		<meta name="twitter:title" content="Introducing LLM360: Fully Transparent Open-Source LLMs">
		<meta name="twitter:description" content="We are thrilled to introduce LLM360, an initiative to open source LLMs that fosters transparency, trust, and collaborative research. When releasing models under LLM360, we strive to make all the details of LLM accessible to everyone.">
		<meta name="twitter:url" content="https://www.llm360.ai/blog/introducing-llm360-fully-transparent-open-source-llms.html">
		<meta name="twitter:image" content="https://www.llm360.ai/images/blog-banner.png">
		<meta name="twitter:site" content="@llm360">
		<meta name="twitter:creator" content="@llm360">

	  <!-- Schema Markup -->
	  <script type="application/ld+json">
				{
			  "@context": "http://schema.org",
			  "@type": "ScholarlyArticle",
			  "headline": "Introducing LLM360: Fully Transparent Open-Source LLMs",
				"description": "Introducing LLM360 - an initiative for fully transparent open-source large language models...",
			  "image": "https://www.llm360.ai/images/blog-banner.png",
				"keywords": "LLM, Open Source, AI, Machine Learning, LLM360",
				"articleSection": "Artificial Intelligence",
			  "author": [
			    {"@type": "Person", "name": "Liu, Zhengzhong"},
			    {"@type": "Person", "name": "Qiao, Aurick"},
			    {"@type": "Person", "name": "Neiswanger, Willie"},
			    {"@type": "Person", "name": " Wang, Hongyi"},
			    {"@type": "Person", "name": " Tan, Bowen"},
			    {"@type": "Person", "name": " Tao, Tianhua"},
			    {"@type": "Person", "name": " Li, Junbo"},
			    {"@type": "Person", "name": " Pangarkar, Omkar"},
			    {"@type": "Person", "name": " Fan, Richard"},
			    {"@type": "Person", "name": " Gu, Yi"},
			    {"@type": "Person", "name": " Miller, Victor"},
			    {"@type": "Person", "name": " Zhuang, Yonghao"},
			    {"@type": "Person", "name": " He, Guowei"},
			    {"@type": "Person", "name": " Li, Haonan"},
			    {"@type": "Person", "name": " Ranjan, Nikhil"},
			    {"@type": "Person", "name": " Shen, Zhiqiang"},
			    {"@type": "Person", "name": " Ren, Xuguang"},
			    {"@type": "Person", "name": " Iriondo, Roberto"},
			    {"@type": "Person", "name": " Mu, Cun"},
			    {"@type": "Person", "name": " Hu, Zhiting"},
			    {"@type": "Person", "name": " Schulze, Mark"},
			    {"@type": "Person", "name": " Nakov, Preslav"},
			    {"@type": "Person", "name": " Baldwin, Tim"},
			    {"@type": "Person", "name": "Xing, Eric"}
				  ],
				  "datePublished": "2023-12-11",
				  "url": "https://www.llm360.ai/blog/introducing-llm360-fully-transparent-open-source-llms.html",
				  "publisher": {
				    "@type": "Organization",
				    "name": "LLM360",
				    "logo": {
				      "@type": "ImageObject",
				      "url": "https://www.llm360.ai/images/logo-highres.png"
				    }
				  },
				  "articleBody": "The recent surge in open-source Large Language Models (LLMs), such as LLaMA,
					Falcon, and Mistral, provides diverse options for AI practitioners and researchers.
					However, most LLMs have only released partial artifacts, such as the final model
					weights or inference code, and technical reports increasingly limit their scope to
					high-level design choices and surface statistics. These choices hinder progress in
					the field by degrading transparency into the training of LLMs and forcing teams to
					rediscover many details in the training process. We present LLM360, an initiative
					to fully open-source LLMs, which advocates for all training code and data, model
					checkpoints, and intermediate results to be made available to the community. The
					goal of LLM360 is to support open and collaborative AI research by making the
					end-to-end LLM training process transparent and reproducible by everyone. As a
					first step of LLM360, we release two 7B parameter LLMs pre-trained from scratch,
					AMBER and CRYSTALCODER, including their training code, data, intermediate
					checkpoints, and analyses (at llm360.ai). We are committed to continually
					pushing the boundaries of LLMs through this open-source effort. More large-scale
					and stronger models are underway and will be released in the future."
				}
		</script>

		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
		<div id="wrapper">

			<!-- Main -->
			<div id="main">
				<div class="inner">
					<section id="blog" class="wrapper style6">
						<header class="major">
							<h1>Introducing <strong>LLM360</strong>: Fully Transparent Open-Source LLMs</h1>
							<p>LLM360 Team  &nbsp | &nbsp December 11, 2023</p>
						</header>
						<div class="content">
							<span class="image banner">
								<img src="../images/blog-banner.png" alt="" />
							</span>
							</br>
							<h2>Introduction</h2>
							<p>
								In recent months, the open-source large language model
								(LLM) community has seen tremendous model contributions.
								However, model weight releases and overview technical
								reports do not contain enough information to cover the
								complexity of LLM training, which hinders openness and
								transparency, the mechanisms behind trustworthy and
								innovative research and science for decades.
							</p>
							<p>
								To this end, we are thrilled to introduce LLM360, an
								initiative to open source LLMs that fosters
								transparency, trust, and collaborative research.  When
								releasing models under LLM360, we strive to make all the
								details of LLM accessible to everyone.
							</p>
							<p>
								Most open-source LLM releases include model weights and
								evaluation results.
								However, additional information is often needed to
								genuinely understand a model's behavior—and this
								information is not typically available to most
								researchers.
								Hence, we commit to releasing all of the intermediate
								checkpoints (up to 360!) collected during training, all
								of the training data (and its mapping to checkpoints),
								all collected metrics (e.g., loss, gradient norm,
								evaluation results), and all source code for
								preprocessing data and model training.
								These additional artifacts can help researchers and
								practitioners to have a deeper look into LLM’s
								construction process and conduct research such as
								analyzing model dynamics.
								We hope that LLM360 can help make advanced LLMs more
								transparent, foster research in smaller-scale labs, and
								improve reproducibility in AI research.
							</p>
							<p>
								To start, we are releasing two models under LLM360:
								Amber-7B and Crystal-7B, which we hope epitomize
								the spirit of open-source and transparent AI
								development.
							</p>
							<p>
								LLM360 is proudly sponsored by Petuum, MBZUAI, and Cerebras.
							</p>
							<hr class="major" />
							<h2>Achieving Transparency and Collaborative Research through LLM360</h2>
							<p>
								The basis of LLM360 is to create a framework that encourages openness and
								research collaboration for large language models. Currently, we include
								all of the following artifacts associated for models in the LLM360 family:

							</p>
							<ul class="feature">
								<li><strong>Frequent Intermediate Model Checkpoints:</strong> During training, model parameters and optimizer states are collected regularly. These artifacts can offer valuable insights for studying LLM training dynamics and how it scales with data, and allows one to resume training at various stages.</li>
								<li><strong>Training Data with Full Data Sequence:</strong> The entire preprocessed, tokenized training dataset is fully disclosed and made publicly available. The dataset is presented exactly in correspondence to the training steps.</li>
								<li><strong>Source Code:</strong> All the code used, including data processing, training, evaluation, and analysis.</li>
								<li><strong>Logs and Metrics:</strong> All the training logs,evaluations and analysis results collected during training are publicly disclosed, also in correspondence to the training steps and data sequence.​</li>
							</ul>
							<p>
								This is just a beginning to our open source efforts and we are committed to continue providing more details.
								Please don’t hesitate to let us know what you want to know! We are thrilled to receive community feedback to continually refine and augment our releases.
							</p>
							<hr class="major" />
							<h2>Amber and Crystal Released under LLM360</h2>
							<div class="row aln-middle" style="margin-top: 1em">
								<div class="col-5 col-12-narrower">
									<span class="image fit" style="width: 70%"><img src="../images/ac_underl360.png" alt="" /></span>
								</div>
								<div class="col-6 col-12-narrower">
									<p>The first two models to be released under LLM360 are Amber and Crystal.
										Amber is a 7B English LLM and Crystal is a 7B code & text LLM.
									</p>
									<p>Both models are released under the Apache 2.0 license.</p>
								</div>
							</div>
							<h3>Amber: Advancing Knowledge and Transparency in LLM Pretraining</h3>
							<p>
								Amber is the inaugural member of the LLM360 family, accompanied by its fine-tuned versions: AmberChat and AmberSafe.
								Amber adopts a model architecture consistent with LLaMA 7B, and we adhere closely to LLaMA's hyperparameters.
								We notice that Amber performs well in MMLU but slightly worse on ARC.
							</p>
							<div class="row aln-center">
								<img src="../images/table_amber.png" style="width: 70%" alt="" />
								<p><strong>Figure 1: Open LLM leaderboard comparisons among a few notable LLMs</strong></p>
							</div>
							<p>Amber's true superpower lies in facilitating a knowledge exchange between the training team and the wider community.
								Along with the customary final model weights, Amber is released with 359 additional model checkpoints (360 total) and the per-step data sequence for each checkpoint.
							</p>
							<p>
								Providing access to these intermediate checkpoints can be beneficial to both researchers looking to advance the capability and understanding of LLMs and industry teams who are pretraining or customizing LLMs for enterprise purposes.
							</p>
							<p>
								We will release  more specific learnings and insights from training Amber,
								stay tuned for further posts! At this moment, we recommend you check out the metrics and analysis below.

							</p>
							<br>
							<div class="row aln-center">
								<a href="https://short.llm360.ai/amber-metrics" target="_blank" class="button4">Wandb</a>
								<a href="https://short.llm360.ai/amber-data" target="_blank" class="button4">Data</a>
								<a href="https://short.llm360.ai/amber-code" target="_blank" class="button4">Code</a>
								<a href="https://short.llm360.ai/amber-model" target="_blank" class="button4">Model</a>
							</div>
							<div class="row aln-center" style="margin-top: 0.1em">
								<span class="image feature"><img src="../images/amber_logo.png" alt=""/></span>
							</div>
							</br>
							<h3>Crystal: Bridging Human Language and Machine Code</h3>
							<p>Crystal is a 7B language model trained on 1.4 trillion tokens, achieving a balance between coding and language ability.</p>
							<div class="row aln-center">
								<img src="../images/table_cc.png" style="width: 100%" alt=""/>
								<p><strong>
									Figure 2: Evaluation comparisons among a few notable code and language models.
									The last column is the average of the language task average and the code task average.
									Crystal strikes a good balance between both language and code tasks.
								</strong></p>
							</div>
							<p>Unlike most previous code LLMs, Crystal is trained using a careful mixture of text and code data to maximize utility in both domains.
								Code data is introduced earlier during the pretraining process (as compared with Code Llama 2 which is fine-tuned on Llama 2 using entirely code data).
								Additionally, we trained Crystal on Python and web programming language, to improve its utility as a programming assistant.
							</p>
							<p>Our experiments show that Crystal achieves a balanced position between LLaMA 2 and Code LLaMA,
								but with fewer training tokens (LLaMA2 7B is trained on 2T tokens and Code LLaMA is trained with additional 600B tokens).
								The graph below plots the language and coding ability of each model based on the tables above.
								As evidenced by the evaluations, LLaMA 2 regresses in language ability when fine-tuned on code.
								More research is needed to fully understand the phenomena, but studying Crystal may offer some insights.
							</p>
							<div class="row aln-center">
								<img src="../images/good_balance.png" style="width: 70%" alt=""/>
								<p><Strong>Figure 3: CRYSTAL shows a good balance
									of language and coding abilities. The y-
									axis is the average over ARC-C, HellaSwag,
									MMLU, and GSM8K. The x-axis is the aver-
									age of MBPP and HumanEval.</Strong></p>
							</div>
							<p>
								By excelling at both language and code, Crystal proves useful for investigating AI Agent and tool use capabilities.
								Crystal is released with 143 checkpoints and all pre training data.
							</p>
							<p>
								The model was trained on the Condor Galaxy 1 supercomputer built by Cerebras and G42.
							</p>
							<br>
							<div class="row aln-center">
								<a href="https://short.llm360.ai/crystalcoder-metrics" target="_blank" class="button5">Wandb</a>
								<a href="https://short.llm360.ai/crystalcoder-data" target="_blank" class="button5">Data</a>
								<a href="https://short.llm360.ai/crystalcoder-code" target="_blank" class="button5">Code</a>
								<a href="https://short.llm360.ai/crystalcoder-model" target="_blank" class="button5">Model</a>
							</div>
							<div class="row aln-center" style="margin-top: 0.1em">
								<span class="image feature"><img src="../images/crystalcoder_logo.png" alt=""/></span>
							</div>
							<hr class="major" />
							<h2>Goals of the LLM360 Framework</h2>
							<ul class="feature">
								<li>
									<span>Increased Accessibility:</span>
									<ul>
										<li>0 GPUs: the community can view all important intermediate results as if training just finished.</li>
										<li>1+ GPUs: intermediate checkpoints can be trained without needing to start from scratch, opening up wider research opportunities.</li>
									</ul>
								</li>
								<li>
									<span>Research Advancement, Reproducibility, and Model Understanding:</span>
									<ul>
										<li>We hope this project lays the groundwork for future research by offering complete, reproducible resources.</li>
										<li>By replicating studies and verifying results, we foster a reliable and transparent research environment.</li>
									</ul>
								</li>
								<li>
									<span>Environmental Responsibility:</span>
									<ul>
										<li>LLM360 promotes sustainable research by sharing all intermediate results that can be extended upon, thereby reducing unnecessary compute.</li>
									</ul>
								</li>
							</ul>
							<hr class="major" />
							<h2>Collaboration and Community in LLM360</h2>
							<h3>Contributing to the LLM360 Ecosystem</h3>
							<p>LLM360 thrives on community involvement, offering various ways for researchers, developers, and enthusiasts to engage and contribute. Here’s a streamlined guide to getting involved:
							<ul class="feature">
								<li>
									<span>Get Involved:</span>
									<ul>
										<li><strong>GitHub:</strong> Our <a href="https://github.com/llm360" target="_blank" rel="noopener">GitHub page</a> is the hub for all code related to LLM360. Explore, modify, or use our code and contribute your improvements.</li>
										<li><strong>HuggingFace:</strong> Access and download LLM360 models on <a href="https://huggingface.co/llm360" target="_blank" rel="noopener">HuggingFace</a>. Experiment with them, and share your findings or applications.</li>
									</ul>
								</li>
								<li>
									<span>Share Your Work:</span>
									<ul>
										<li><strong>Research Contributions:</strong> If you’ve used Amber or Crystal for research, we encourage you to share your results. Your insights can help enhance these models.</li>
										<li><strong>Share Results:</strong> Your analysis results on any of the checkpoints are more than welcome. Feel free to share with us metrics you compute, we will host selected metrics on our public Weights & Biases dashboard.</li>
									</ul>
								</li>
								<li>
									<span>Feedback and Suggestions:</span>
									<ul>
										<li><strong>Feedback Form:</strong> We value your input. <a href="../index.html#contact">Use this form</a> to provide feedback or suggest improvements. Let us know what you want to know more about LLMs!</li>
										<li><strong>Join Discussions:</strong> Engage with peers on our forums. Share experiences, ask questions, and exchange ideas.</li>
									</ul>
								</li>
								<li>
									<span>Collaborate</span>
									<ul>
										<li><strong>Partnership Opportunities: </strong>If you're interested in collaborating on a project or have an idea, we’d love to hear from you.</li>
									</ul>
								</li>
							</ul>
							</p>
							<hr class="major" />
							<h2>What's Ahead for LLM360</h2>
							<p>
								LLM360 is on a mission to expand and deepen the influence of AI research by providing fully accessible, open-source LLMs. We are committed to being fully open and sharing more high quality information on LLMs.
							</p>
							<p>
								Join our global community of researchers, developers, and AI enthusiasts to explore, enhance, and expand models under LLM360.  Together, we can make AI research more open, transparent, and trustworthy.
							</p>
							<hr class="major" />
							<h2>Resources</h2>
							<ul>
								<li><a href="https://huggingface.co/LLM360" target="_blank" rel="noopener">Download the models</a></li>
								<li><a href="https://github.com/llm360" target="_blank" rel="noopener">Access our codebase</a></li>
								<li><a href="paper.pdf" target="_blank">Read the paper</a></li>
							</ul>
							<hr class="major" />
							<h2><label for="citation">Citation</label></h2>
							<p> If you use LLM360, feel free to cite: </p>
							<div class="box" background-color="#eee" border="1px" solid="#999" display="block" padding="20px">
										<textarea id="citation" rows="9" cols="50" readonly>@article{liu2023llm360,
title={LLM360: Towards Fully Transparent Open-Source LLMs},
author={Liu, Zhengzhong and Qiao, Aurick and Neiswanger, Willie and Wang, Hongyi and Tan, Bowen and Tao, Tianhua and Li, Junbo and Wang, Yuqi and Sun, Suqi and Pangarkar, Omkar and Fan, Richard and Gu, Yi and Miller, Victor and Zhuang, Yonghao and He, Guowei and Li, Haonan and Koto, Fajri and Tang, Liping and Ranjan, Nikhil and Shen, Zhiqiang and Ren, Xuguang and Iriondo, Roberto and Mu, Cun and Hu, Zhiting and Schulze, Mark and Nakov, Preslav and Baldwin, Tim and Xing, Eric},
year={2023}}
										</textarea>
								<button onclick="copyCitation()">Copy Citation</button>

								<script>
									function copyCitation() {
										var copyText = document.getElementById("citation");
										copyText.select();
										document.execCommand("copy");
									}
								</script>
							</div>
						</div>
					</section>
				</div>
			</div>
			<!-- Sidebar -->
			<div id="sidebar">
				<div class="inner">
					<!-- Menu -->
					<nav id="menu">
						<a href="../index.html">
							<figure class="hover-rotate">
								<img src="../images/logo-highres.png" alt="logo" />
							</figure>
						</a>
						<header>
							<h1><a href="../index.html">LLM360</a></h1>
						</header>
						<ul>
							<li><a href="../index.html#crystal">Models</a></li>
							<li><a href="../index.html#research">Research</a></li>
							<li><a href="../index.html#resources">Resources</a></li>
							<li><a href="../index.html#contact">Contact</a></li>
							<li><a href="about.html">About</a></li>
						</ul>
					</nav>
					<!-- Footer -->
					<footer id="footer">
						<p>
							LLM360, proudly sponsored by Petuum, MBZUAI, and Cerebras, is dedicated to advancing the field of AI by providing comprehensive access to large language models.<br>
							Our mission is to foster an ecosystem of collaboration, transparency, and innovation in AI research and applications.
						</p>
						<ul class="icons">
							<li><a href="https://twitter.com/llm360" target="_blank" class="icon brands circle fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://github.com/LLM360" target="_blank" class="icon brands circle fa-github"><span class="label">Github</span></a></li>
							<li><a href="mailto:team@llm360.ai" target="_blank" class="icon circle fa-envelope"><span class="label">Email</span></a></li>
						</ul>
						<p class="copyright">&copy; LLM360 2023. All rights reserved.</p>
					</footer>

				</div>
			</div>
			<a id="buttonToTop"></a>
		</div>
		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>
